# Application
APP_NAME=DeepThought
DEBUG=false
LOG_LEVEL=INFO

# AWS
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=dummy
AWS_SECRET_ACCESS_KEY=dummy

# DynamoDB
DYNAMODB_TABLE_NAME=deepthought-calculations
DYNAMODB_ENDPOINT_URL=http://localhost:8000  # For local DynamoDB

# LLM Configuration
# Provider: "ollama" (local, free) or "anthropic" (cloud, requires API key)
LLM_PROVIDER=ollama
# Model name - examples:
#   Ollama: "llama3.2", "mistral", "deepseek-r1", "qwen2.5"
#   Anthropic: "claude-3-haiku-20240307", "claude-3-sonnet-20240229"
LLM_MODEL=llama3.2

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434

# Anthropic Configuration (for cloud LLM)
# Only required if LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=add-your-anthropic-api-key-here

# Setup additional LLM providers as needed below
OPENAI_API_KEY=add-your-openai-api-key-here
GOOGLE_API_KEY=add-your-google-api-key-here
COHERE_API_KEY=add-your-cohere-api-key-here
GROQ_API_KEY=add-your-groq-api-key-here
TOGETHER_API_KEY=add-your-together-api-key-here
FIREWORKS_API_KEY=add-your-fireworks-api-key-here


# CORS (comma-separated origins)
CORS_ORIGINS=["http://localhost:3000"]
